# -*- coding: utf-8 -*-
"""Batch Size Testing_Vanguard Defense_Week 4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17BZiMPUGfFiiuT8IS5CQ5JnTmP-MuTIj
"""

!pip install ultralytics

# Imports
import os
import time
import shutil
import json
from pathlib import Path

# Cloning repo and changing directory
repo_url = "https://github.com/noahpaden12/Week_4_Vanguard_Defense_Internship_Project.git"
repo_dir = "/content/Week_4_Vanguard_Defense_Internship_Project"

if os.path.exists(repo_dir):
    shutil.rmtree(repo_dir)

!git clone $repo_url

# Commented out IPython magic to ensure Python compatibility.

# %cd $repo_dir

# Model for trainer
import importlib.util

trainer_path = os.path.join(repo_dir, "model_trainer.py")
spec = importlib.util.spec_from_file_location("model_trainer", trainer_path)
trainer = importlib.util.module_from_spec(spec)
spec.loader.exec_module(trainer)

# Testing different batch sizes
batch_sizes = [8, 16, 32] # You can change this list
results = []

for bs in batch_sizes:
  print(f"\n==============================")
  print(f"Training with batch size: {bs}")
  print(f"==============================")

  start_time = time.time()

  # Calling the updated function from script
  trainer.train_yolov8(
      json_annotations="dataset_v1/test/annotations.json",
      dataset_folder="dataset_v1",
      epochs=20,
      batch=bs,
      imgsz=640,
      lr0=0.01
  )

  end_time = time.time()
  duration = round(end_time - start_time, 2)

  # Loading training results from Ultralytics YOLO output
  metrics_path = Path("runs/train/manual_yolov8n_training/results.csv")
  if metrics_path.exists():
      import pandas as pd
      df = pd.read_csv(metrics_path)
      final_epoch = df.iloc[-1]
      accuracy = final_epoch.get("metrics/mAP50(B)", None)
      loss = final_epoch.get("train/cls_loss", None)
  else:
      accuracy = None
      loss = None

  result = {
      "batch_size": bs,
      "train_time_sec": duration,
      "accuracy": accuracy,
      "loss": loss

  }

  results.append(result)
  print(f" Result: {result}")

# Saving results
results_path = "/content/batch_size_results.json"
with open(results_path, "w") as f:
    json.dump(results, f, indent=2)

print(f"\n All results saved to {results_path}")